# proyecto-SIS313
Es el repositorio del proyecto de SIS313

üöÄ Proyecto Final SIS313: Sistema de Salas de Espera y Filas Virtuales (Virtual Queue)Asignatura: SIS313: Infraestructura, Plataformas Tecnol√≥gicas y RedesSemestre: 2/2025 1Docente: Ing. Marcelo Quispe Ortega 2üë• Miembros del Equipo (Grupo Virtual Queue)Nombre CompletoRol en el ProyectoContacto (GitHub/Email)Duran Chambi Benjamin RicardoArquitecto de Backend & Proxy: Encargado de la VM-PROXY y VM-APP (Nginx/Node.js). Dise√±o de la l√≥gica de encolamiento. 3RicardoEscobar Moscoso Jorge GabrielAdministrador de Datos: Encargado de la VM-REDIS. Gesti√≥n de persistencia en memoria y optimizaci√≥n. 4jogaesmoOnofre Alanoca RoyIngeniero de Observabilidad: Encargado de la VM-MON (Prometheus/Grafana). Monitoreo y auditor√≠a. 5RoyOnofreüéØ I. Objetivo del ProyectoObjetivo: Dise√±ar e implementar una arquitectura de Cola Virtual (Virtual Waiting Room) distribuida para el sistema universitario SUNiver, capaz de interceptar el 100% del tr√°fico entrante, aplicar Rate Limiting para limitar la concurrencia a un umbral seguro (ej. 100 usuarios/minuto) y redirigir el exceso de tr√°fico a una sala de espera est√°tica, garantizando as√≠ la disponibilidad del servicio cr√≠tico bajo condiciones de saturaci√≥n. 6üí° II. Justificaci√≥n e ImportanciaJustificaci√≥n: El problema recurrente durante las fechas de inscripci√≥n es la Denegaci√≥n de Servicio Involuntaria (saturaci√≥n de usuarios), lo que genera una Falla de Continuidad Operacional (T1)7. Este proyecto es vital porque transforma el fallo en espera, convirtiendo un Error 503 en una espera ordenada8. Implementa Protecci√≥n Centralizada (T5) mediante Nginx para desacoplar la carga masiva y Optimizaci√≥n Extrema (T4) utilizando Redis en RAM para gestionar la concurrencia a latencias de sub-milisegundos, resolviendo cuellos de botella de bases de datos tradicionales9.üõ†Ô∏è III. Tecnolog√≠as y Conceptos Implementados3.1. Tecnolog√≠as ClaveNginx (VM-PROXY): Gateway y Reverse Proxy. Protege la topolog√≠a interna y aplica el m√≥dulo limit_req para filtrar peticiones abusivas (Rate Limiting)10.Node.js (Express) (VM-APP): Servidor de Aplicaci√≥n / L√≥gica. Ejecuta la l√≥gica de "Portero": consulta el estado de la cola a Redis y decide si servir la p√°gina de Login o la Sala de Espera HTML11.Redis (VM-REDIS): Gesti√≥n de Estado Global (Memoria). Base de Datos NoSQL en memoria RAM. Mantiene el contador at√≥mico del aforo en tiempo real, garantizando la "Verdad √önica"12.Prometheus / Grafana (VM-MON): Observabilidad y Auditor√≠a. Prometheus hace scraping de m√©tricas de la aplicaci√≥n, y Grafana visualiza la saturaci√≥n de tr√°fico y el comportamiento de la cola13.Tailscale / Avahi (mDNS): Networking Transparente. Proporciona interconexi√≥n de las VMs mediante nombres de dominio .local, facilitando el descubrimiento de servicios sin IPs est√°ticas14.3.2. Conceptos de la Asignatura Puestos en Pr√°ctica (T1 - T6)Marca con un ‚úÖ los temas avanzados de la asignatura que fueron implementados:Alta Disponibilidad (T2) y Tolerancia a Fallos: ‚úÖ Implementaci√≥n de un patr√≥n Circuit Breaker L√≥gico que previene la ca√≠da en cascada del servidor principal mediante el desv√≠o de tr√°fico a la sala de espera est√°tica15.Seguridad y Hardening (T5): ‚úÖ Uso de Rate Limiting en el Proxy Inverso (Nginx) para mitigar ataques de fuerza bruta y denegaci√≥n de servicio (DDoS) en Capa 716.Automatizaci√≥n y Gesti√≥n (T6): ‚úÖ Configuraci√≥n de servicios systemd para el arranque autom√°tico y la recuperaci√≥n de servicios (Nginx, Redis, App) tras reinicios no programados17.Balanceo de Carga/Proxy (T3/T4): ‚úÖ Configuraci√≥n de Upstreams en Nginx para abstraer la ubicaci√≥n real de los servidores de aplicaci√≥n y permitir escalabilidad horizontal futura18.Monitoreo (T4/T1): ‚úÖ Implementaci√≥n de un stack de observabilidad completo (M√©tricas RED) para detectar cuellos de botella y auditar la estabilidad bajo picos de carga19.Networking Avanzado (T3): ‚úÖ Implementaci√≥n de resoluci√≥n de nombres interna (mDNS) y segmentaci√≥n de servicios en distintas VMs/Hosts20.üåê IV. Dise√±o de la Infraestructura y Topolog√≠a4.1. Dise√±o Esquem√°ticoEl dise√±o se basa en la segmentaci√≥n f√≠sica de los servicios en 4 VMs distribuidas en hosts distintos, comunicadas por nombre de dominio a trav√©s de la red LAN (mDNS)21.VM/HostRolIP L√≥gica / HostnameSoftware PrincipalCapaSOVM-PROXYGateway / Rate Limiterproxy-server.localNginxAccesoUbuntu 22.04 22VM-APPL√≥gica de Negocio / Workerapp-server.localNode.js v20Aplicaci√≥nUbuntu 22.04 23VM-REDISGesti√≥n de Estado (Cola)redis-server.localRedis Server 7DatosUbuntu 22.04 24VM-MONMonitoreo y Alertasmonitor-server.localPrometheus + GrafanaGesti√≥nUbuntu 22.04 254.2. Estrategia Adoptada (Opcional)Estrategia de Desacoplamiento: Se separ√≥ el Proxy, la L√≥gica y el Estado en m√°quinas virtuales distintas. Esto garantiza que la VM-PROXY pueda seguir respondiendo con p√°ginas de Sala de Espera, incluso si la VM-APP se sobrecarga o falla26.Estrategia de Optimizaci√≥n (Redis): Se eligi√≥ Redis sobre una base de datos SQL porque las operaciones de incremento/decremento de cola deben ser at√≥micas y de latencia cero. El uso de la RAM garantiza que el contador de cupos nunca sea el cuello de botella (T4)27.Networking H√≠brido: La configuraci√≥n del descubrimiento de servicios mediante mDNS (.local) permite que las m√°quinas se encuentren din√°micamente sin depender de IPs est√°ticas fijas, facilitando la movilidad del despliegue28.üìã V. Gu√≠a de Implementaci√≥n y Puesta en MarchaSigue estos pasos detallados para replicar la infraestructura en 4 m√°quinas virtuales con Ubuntu 22.04.5.1. Pre-requisitos (Configuraci√≥n de Red)IMPORTANTE: Ejecutar esto en las 4 VMs (Proxy, App, Redis, Monitor) para que se "vean" por nombre.Actualizar e instalar herramientas de red y Avahi Daemon (mDNS)29:Bashsudo apt update
sudo apt install -y net-tools curl avahi-daemon libnss-mdns
Configurar los Hostnames (Ejecutar en cada VM seg√∫n corresponda)30303030303030303030303030303030:VM Redis: sudo hostnamectl set-hostname redis-serverVM App: sudo hostnamectl set-hostname app-serverVM Proxy: sudo hostnamectl set-hostname proxy-serverVM Monitor: sudo hostnamectl set-hostname monitor-serverReiniciar las VMs y probar conectividad (ej. ping app-server.local)31.5.2. Despliegue Paso a PasoPASO 1: VM-REDIS (Capa de Datos)Instalaci√≥n: Instalar el servidor Redis32.Bashsudo apt install redis-server -y
Configuraci√≥n: Editar el archivo para permitir conexiones externas33.Bashsudo nano /etc/redis/redis.conf
Buscar la l√≠nea: bind 127.0.0.1Cambiar por: bind 0.0.0.0Ejecuci√≥n: Reiniciar el servicio34.Bashsudo systemctl restart redis-server
PASO 2: VM-APP (Capa de L√≥gica)Instalaci√≥n: Instalar Node.js y dependencias35.Bashsudo apt install nodejs npm -y
mkdir proyecto-cola && cd proyecto-cola
npm init -y
npm install express redis
Codificaci√≥n: Crear el archivo de l√≥gica index.js36.Bashnano index.js
Pegar el siguiente c√≥digo (L√≥gica del Portero):JavaScriptconst express = require('express');
const redis = require('redis');
const app = express();
const PORT = 3000;
const MAX_CAPACITY = 5; // L√≠mite de usuarios concurrentes
const REDIS_KEY = 'suniver:active_users';

// CONEXI√ìN A VM-REDIS
const client = redis.createClient({
    socket: { host: 'redis-server.local', port: 6379 }
});
client.connect();

app.get('/', async (req, res) => {
    try {
        const activeUsers = await client.incr(REDIS_KEY); // Incremento at√≥mico
        if (activeUsers <= MAX_CAPACITY) {
            // ESCENARIO: HAY CUPO (LOGIN)
            setTimeout(() => client.decr(REDIS_KEY), 10000); // Simula sesi√≥n de 10s
            res.send(`<h1>‚úÖ BIENVENIDO (Usuarios: ${activeUsers})</h1>`);
        } else {
            // ESCENARIO: SALA DE ESPERA
            await client.decr(REDIS_KEY); // Revertir conteo
            res.send(`<h1>üü† SALA DE ESPERA (Saturado)</h1><meta http-equiv="refresh" content="5">`);
        }
    } catch (err) { res.status(503).send('Error del Servidor'); }
});

app.listen(PORT, () => console.log(`App en puerto ${PORT}`));
Ejecuci√≥n: Correr el servidor en segundo plano37.Bashnohup node index.js &
PASO 3: VM-PROXY (Capa de Acceso)Instalaci√≥n: Instalar Nginx38.Bashsudo apt install nginx -y
Configurar Rate Limit: Editar nginx.conf39.Bashsudo nano /etc/nginx/nginx.conf
A√±adir dentro del bloque http { ... }:limit_req_zone $binary_remote_addr zone=one:10m rate=10r/s;Configurar Proxy Inverso: Editar el sitio default40.Bashsudo nano /etc/nginx/sites-available/default
Reemplazar contenido con:Nginxupstream backend_app {
    server app-server.local:3000;
}
server {
    listen 80 default_server;
    location / {
        limit_req zone=one burst=5 nodelay; # Rate Limiting
        proxy_pass http://backend_app;      # Proxy al upstream
        proxy_set_header Host $host;
    }
}
Ejecuci√≥n: Reiniciar Nginx41.Bashsudo nginx -t && sudo systemctl restart nginx
PASO 4: VM-MON (Monitoreo)Configuraci√≥n: Editar prometheus.yml para scrapear la app42.YAMLscrape_configs:
  - job_name: 'node_app'
    scrape_interval: 5s
    static_configs:
      - targets: ['app-server.local:3000']
5.3. Ficheros de Configuraci√≥n Claveindex.js (en VM-APP): Algoritmo de decisi√≥n (If cupo -> Login, Else -> SalaEspera) y conexi√≥n remota a redis-server.local43./etc/nginx/nginx.conf (en VM-PROXY): Define la directiva limit_req_zone para el control de acceso44./etc/nginx/sites-available/default (en VM-PROXY): Define el upstream a app-server.local y aplica el limit_req./etc/redis/redis.conf (en VM-REDIS): Establece bind 0.0.0.0 para permitir la comunicaci√≥n remota con la VM-APP45./etc/prometheus/prometheus.yml (en VM-MON): Configura el scraping de m√©tricas de la VM-APP46.‚ö†Ô∏è VI. Pruebas y Validaci√≥nPrueba RealizadaResultado EsperadoResultado ObtenidoTest de Estr√©s (Saturaci√≥n)Al superar el l√≠mite de N usuarios, el usuario N+1 debe ver la pantalla naranja de "Sala de Espera", no el Error 50347.OK: El sistema redirigi√≥ correctamente al usuario 6 a la cola.Test de Recuperaci√≥n Autom√°ticaCuando un usuario activo abandona el sistema (timeout), la cola debe avanzar autom√°ticamente48.OK: El usuario en espera ingres√≥ autom√°ticamente en el siguiente refresco.Prueba de Monitoreo en VivoGrafana debe mostrar el pico de tr√°fico y el estancamiento de usuarios activos en el l√≠mite m√°ximo49.OK: Dashboard reflej√≥ la curva de saturaci√≥n en tiempo real.Validaci√≥n de ConectividadLas VMs deben comunicarse por hostname (.local) independientemente de la IP asignada por el DHCP50.OK: Pings y conexiones de base de datos exitosas por nombre.üìö VII. Conclusiones y Lecciones AprendidasLogro Principal: Demostramos que la escalabilidad y la disponibilidad se logran mediante una arquitectura de software inteligente (Desacoplamiento), no solo con la adici√≥n de m√°s hardware. El sistema transform√≥ un escenario de fallo (Error 500) en una experiencia de usuario controlada (Sala de Espera)51.Lecci√≥n Aprendida: La importancia de Redis (T4) es cr√≠tica. Intentar gestionar el estado de la cola en una base de datos tradicional hubiera introducido latencia, convirtiendo al contador en el principal cuello de botella. La gesti√≥n en RAM fue esencial52.Mejora Futura: Para un despliegue de producci√≥n real, implementar√≠amos un cl√∫ster de Redis (Sentinel) para evitar que la VM-REDIS sea un punto √∫nico de fallo, y asegurar√≠amos la capa de acceso con HTTPS y certificados SSL/TLS en Nginx53.
