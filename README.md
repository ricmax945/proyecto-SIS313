# proyecto-SIS313

# üöÄ Proyecto Final SIS313: Sistema de Salas de Espera y Filas Virtuales (Virtual Queue)

> **Asignatura:** SIS313: Infraestructura, Plataformas Tecnol√≥gicas y Redes<br>
> **Semestre:** 2/2025<br>
> **Docente:** Ing. Marcelo Quispe Ortega

## üë• Miembros del Equipo (Grupo Virtual Queue)

| Nombre Completo | Rol en el Proyecto | Contacto (GitHub/Email) |
| :--- | :--- | :--- |
| **Duran Chambi Benjamin Ricardo** | Arquitecto de Backend & Proxy (Nginx/Node.js) | Ricardo |
| **Escobar Moscoso Jorge Gabriel** | Administrador de Datos (Redis/Persistencia) | [jogaesmo](https://github.com/jogaesmo) |
| **Onofre Alanoca Roy** | Ingeniero de Observabilidad (Prometheus/Grafana) | [RoyOnofre](https://github.com/RoyOnofre) |

## üéØ I. Objetivo del Proyecto

> **Objetivo:** Dise√±ar e implementar una arquitectura de **Cola Virtual (Virtual Waiting Room)** distribuida para el sistema universitario SUNiver, capaz de interceptar el 100% del tr√°fico entrante, aplicar **Rate Limiting** para limitar la concurrencia a un umbral seguro (ej. 100 usuarios/minuto) y redirigir el exceso de tr√°fico a una sala de espera est√°tica, garantizando as√≠ la **disponibilidad del servicio cr√≠tico** bajo condiciones de saturaci√≥n.

## üí° II. Justificaci√≥n e Importancia

> **Justificaci√≥n:** El problema recurrente durante las fechas de inscripci√≥n es la **Denegaci√≥n de Servicio Involuntaria** (saturaci√≥n de usuarios), lo que genera una Falla de Continuidad Operacional (T1). Este proyecto transforma el fallo en espera, convirtiendo un Error 503 en una espera ordenada. Implementa **Protecci√≥n Centralizada (T5)** mediante Nginx para desacoplar la carga y **Optimizaci√≥n Extrema (T4)** utilizando Redis en RAM para gestionar la concurrencia a latencias de sub-milisegundos, resolviendo los cuellos de botella de las bases de datos tradicionales.

## üõ†Ô∏è III. Tecnolog√≠as y Conceptos Implementados

### 3.1. Tecnolog√≠as Clave

* **Nginx (VM-PROXY):** [Funci√≥n: Gateway y Reverse Proxy. Protege la topolog√≠a interna y aplica el m√≥dulo `limit_req` para filtrar peticiones abusivas (Rate Limiting).]
* **Node.js (Express) (VM-APP):** [Funci√≥n: L√≥gica de "Portero". Consulta el estado de la cola a Redis y decide si servir la p√°gina de Login o la Sala de Espera HTML.]
* **Redis (VM-REDIS):** [Funci√≥n: Base de Datos NoSQL en memoria RAM. Mantiene el contador at√≥mico del aforo en tiempo real, garantizando la "Verdad √önica".]
* **Prometheus / Grafana (VM-MON):** [Funci√≥n: Observabilidad. Prometheus hace scraping de m√©tricas y Grafana visualiza la saturaci√≥n de tr√°fico y el comportamiento de la cola.]
* **Tailscale / Avahi (mDNS):** [Funci√≥n: Networking Transparente. Interconexi√≥n de las VMs mediante nombres de dominio `.local`, facilitando el descubrimiento de servicios sin IPs est√°ticas.]

### 3.2. Conceptos de la Asignatura Puestos en Pr√°ctica (T1 - T6)

Marca con un ‚úÖ los temas avanzados de la asignatura que fueron implementados:

* **Alta Disponibilidad (T2) y Tolerancia a Fallos:** ‚úÖ [Implementaci√≥n de un patr√≥n Circuit Breaker L√≥gico que previene la ca√≠da en cascada del servidor principal desviando tr√°fico a sala de espera.]
* **Seguridad y Hardening (T5):** ‚úÖ [Uso de Rate Limiting en el Proxy Inverso (Nginx) para mitigar ataques de fuerza bruta y DDoS en Capa 7.]
* **Automatizaci√≥n y Gesti√≥n (T6):** ‚úÖ [Configuraci√≥n de servicios `systemd` para el arranque autom√°tico y la recuperaci√≥n de servicios tras reinicios.]
* **Balanceo de Carga/Proxy (T3/T4):** ‚úÖ [Configuraci√≥n de Upstreams en Nginx para abstraer la ubicaci√≥n real de los servidores de aplicaci√≥n.]
* **Monitoreo (T4/T1):** ‚úÖ [Implementaci√≥n de un stack de observabilidad completo (M√©tricas RED) para detectar cuellos de botella.]
* **Networking Avanzado (T3):** ‚úÖ [Implementaci√≥n de resoluci√≥n de nombres interna (mDNS) y segmentaci√≥n de servicios en distintas VMs.]

## üåê IV. Dise√±o de la Infraestructura y Topolog√≠a

### 4.1. Dise√±o Esquem√°tico

El dise√±o se basa en la segmentaci√≥n f√≠sica de los servicios en 4 VMs distribuidas en hosts distintos.

> 
| VM/Host | Rol | Hostname (.local) | Software Principal | Capa | SO |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **VM-PROXY** | Gateway / Rate Limiter | `proxy-server.local` | Nginx | Acceso | Ubuntu 22.04 |
| **VM-APP** | L√≥gica / Worker | `app-server.local` | Node.js v20 | Aplicaci√≥n | Ubuntu 22.04 |
| **VM-REDIS** | Gesti√≥n de Estado | `redis-server.local` | Redis Server 7 | Datos | Ubuntu 22.04 |
| **VM-MON** | Monitoreo | `monitor-server.local` | Prometheus + Grafana | Gesti√≥n | Ubuntu 22.04 |

### 4.2. Estrategia Adoptada

* **Estrategia de Desacoplamiento:** Se separ√≥ el Proxy, la L√≥gica y el Estado. Esto garantiza que la VM-PROXY pueda seguir respondiendo con la Sala de Espera incluso si la VM-APP falla.
* **Estrategia de Optimizaci√≥n (Redis):** Se eligi√≥ Redis sobre SQL porque las operaciones de incremento/decremento deben ser at√≥micas y de latencia cero (RAM).

## üìã V. Gu√≠a de Implementaci√≥n y Puesta en Marcha

### 5.1. Pre-requisitos (Networking)
Ejecutar en **TODAS** las VMs para habilitar resoluci√≥n por nombre:

```bash
sudo apt update
sudo apt install -y net-tools curl avahi-daemon libnss-mdns
# Verificar conectividad:
ping app-server.local

5.2. Despliegue Detallado (Paso a Paso)
Paso 1: Configurar Base de Datos (VM-REDIS)
Instalar Redis: sudo apt install redis-server -y

Permitir conexiones remotas editando el archivo redis.conf:

Bash

sudo nano /etc/redis/redis.conf
# CAMBIAR: bind 127.0.0.1  --> POR: bind 0.0.0.0

Reiniciar: sudo systemctl restart redis-serverPaso 2: Configurar Aplicaci√≥n (VM-APP)Instalar Node.js: sudo apt install nodejs npm -yCrear proyecto:Bashmkdir proyecto && cd proyecto
npm init -y
npm install express redis
nano index.js
C√≥digo Fuente (index.js):JavaScriptconst express = require('express');
const redis = require('redis');
const app = express();
const client = redis.createClient({ socket: { host: 'redis-server.local', port: 6379 } });
client.connect();

app.get('/', async (req, res) => {
    const active = await client.incr('users');
    if (active <= 5) { // Aforo maximo 5
        setTimeout(() => client.decr('users'), 10000); // Simula 10s de uso
        res.send(`<h1>‚úÖ BIENVENIDO (Usuarios: ${active})</h1>`);
    } else {
        await client.decr('users');
        res.send(`<h1>üü† SALA DE ESPERA</h1><meta http-equiv="refresh" content="5">`);
    }
});
app.listen(3000);
Ejecutar: nohup node index.js &Paso 3: Configurar Proxy y Rate Limit (VM-PROXY)Instalar Nginx: sudo apt install nginx -yEditar nginx.conf para agregar el l√≠mite:Bashsudo nano /etc/nginx/nginx.conf
# Agregar en bloque http:
limit_req_zone $binary_remote_addr zone=one:10m rate=10r/s;
Configurar el sitio en /etc/nginx/sites-available/default:Nginxupstream backend { server app-server.local:3000; }
server {
    listen 80 default_server;
    location / {
        limit_req zone=one burst=5 nodelay;
        proxy_pass http://backend;
    }
}
Reiniciar: sudo systemctl restart nginx5.3. Ficheros de Configuraci√≥n Clave/etc/redis/redis.conf: Configuraci√≥n de Bind IP.index.js: L√≥gica de negocio y conexi√≥n a Redis./etc/nginx/nginx.conf: Definici√≥n de Zona de Rate Limit.‚ö†Ô∏è VI. Pruebas y Validaci√≥nPrueba RealizadaResultado EsperadoResultado ObtenidoTest de Estr√©sAl superar el l√≠mite de N usuarios, el usuario N+1 ve la "Sala de Espera".‚úÖ OK: Redirecci√≥n correcta.Test de Recuperaci√≥nCuando un usuario sale, la cola avanza autom√°ticamente.‚úÖ OK: Ingreso autom√°tico.Monitoreo en VivoGrafana muestra el pico de tr√°fico y saturaci√≥n.‚úÖ OK: M√©tricas visibles.ConectividadLas VMs se comunican por hostname (.local).‚úÖ OK: Pings exitosos.üìö VII. Conclusiones y Lecciones AprendidasSe logr√≥ implementar una arquitectura resiliente donde Redis en RAM fue la clave para eliminar la latencia en el conteo de usuarios. El desacoplamiento de servicios permiti√≥ que el Proxy siguiera funcionando (mostrando la sala de espera) incluso bajo estr√©s m√°ximo de la aplicaci√≥n.
